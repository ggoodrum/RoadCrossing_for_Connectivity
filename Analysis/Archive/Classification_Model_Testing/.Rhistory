# Load in data
data.stream <- read.csv(raw.data,
header = TRUE)
# Generate barrier data
data.barriers <- data.stream %>% filter(UID != "")
# Extract sampled barriers
data.sample <- data.stream %>% filter(Sampled == TRUE & Pass_WDFG != 'Unknown')
# Summarized sampled barriers by presence/absence
data.sample <- data.sample %>% mutate(Barrier_Present = ifelse(Pass_WDFG == '1.0', 'Absent', 'Present'))
pres.sum <- data.sample %>% group_by(Barrier_Present) %>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))
pres.sum
# Summarize sampled barrier types
pass.sum <- get_barrier_pass_probability(data = data.sample,
# typeObserved = Barrier_Observed,
passObserved = Pass_WDFG)
pass.sum
# ---------------------------------------------------------------------
generate_binary_model <- function(data.sample,
response,
predictors,
seed.split,
perc.train,
n.fold,
type.sample,
type.model,
type.metric){
# Initialize output list
out.list <- list()
# Select data for model
data.model <- data.sample %>% select(all_of({{response}}), all_of({{predictors}})) %>%
mutate_if(is.character, as.factor)
# Split train/test datasets
set.seed(seed.split)
train.Index <- createDataPartition(data.model[,{{response}}],
p = perc.train,
list = FALSE, times = 1)
# Generate train/test split
data.train <- data.model[train.Index,]
data.test <- data.model[-train.Index,]
# Tune model parameters
ctrl <- trainControl(method = 'cv', number = n.fold, returnResamp = 'none',
summaryFunction = twoClassSummary, classProbs = TRUE)
# Downsample for model training
ctrl$sampling <- type.sample
# Declare formula
model.formula <- reformulate('.', response = response)
# Train model
model.out <- train(model.formula,
data = data.train,
method = type.model,
trControl = ctrl,
metric = type.metric,
verbose = FALSE)
# Model evaluation - accuracy and kappa
predictions <- predict(object = model.out, data.test[,{{predictors}}], type = 'raw')
predictions.cm <- confusionMatrix(data.test[,{{response}}], as.factor(predictions))
# print(predictions.cm$overall[1])
# Model evaluation - AUC
predictions.prob <- predict(object = model.out, data.test[,{{predictors}}], type = 'prob')
predictions.auc <- roc(ifelse(data.test[,{{response}}] == 'Present', 1, 0), predictions.prob[[2]])
# print(predictions.auc$auc)
# Generate model evaluation dataframe
tbl.eval <- data.frame(Model_seed = seed.split,
Accuracy = predictions.cm$overall[1],
Kappa = predictions.cm$overall[2],
AUC = predictions.auc$auc[1],
row.names = NULL)
# Generate names for list output
name.model <- paste0('Model_Seed_', seed.split)
name.eval  <- paste0('Eval_Seed_', seed.split)
# Assign outputs to list
out.list[[name.model]] <- model.out
out.list[[name.eval]] <- tbl.eval
# Return output model
return(out.list)
}
generate_multiClass_model <- function(data.sample,
response,
predictors,
seed.split,
perc.train,
n.fold,
type.sample,
type.model,
type.metric){
# Initialize output list
out.list <- list()
# Select data for model
data.model <- data.sample %>% select(all_of({{response}}), all_of({{predictors}})) %>%
mutate_if(is.character, as.factor)
# Split train/test datasets
set.seed(seed.split)
train.Index <- createDataPartition(data.model[,{{response}}],
p = perc.train,
list = FALSE, times = 1)
# Generate train/test split
data.train <- data.model[train.Index,]
data.test <- data.model[-train.Index,]
# Tune model parameters
ctrl <- trainControl(method = 'cv', number = n.fold, returnResamp = 'none',
summaryFunction = multiClassSummary, classProbs = TRUE)
# Downsample for model training
ctrl$sampling <- type.sample
# Declare formula
model.formula <- reformulate('.', response = response)
# Train model
model.out <- train(model.formula,
data = data.train,
method = type.model,
trControl = ctrl,
metric = type.metric,
verbose = FALSE)
# Model evaluation - accuracy and kappa
predictions <- predict(object = model.out, data.test[,{{predictors}}], type = 'raw')
predictions.cm <- confusionMatrix(data.test[,{{response}}], as.factor(predictions))
# print(predictions.cm$overall[1])
# Model evaluation - AUC
predictions.prob <- predict(object = model.out, data.test[,{{predictors}}], type = 'prob')
predictions.auc <- multiclass.roc(data.test[,{{response}}], predictions.prob)
# print(predictions.auc$auc)
# Generate model evaluation dataframe
tbl.eval <- data.frame(Model_seed = seed.split,
Accuracy = predictions.cm$overall[1],
Kappa = predictions.cm$overall[2],
AUC = predictions.auc$auc[1],
row.names = NULL)
# Generate names for list output
name.model <- paste0('Model_Seed_', seed.split)
name.eval  <- paste0('Eval_Seed_', seed.split)
# Assign outputs to list
out.list[[name.model]] <- model.out
out.list[[name.eval]] <- tbl.eval
# Return output model
return(out.list)
}
generate_modeled_barriers <- function(data.sample,
data.predict,
type.predicted,
type.observed,
pass.observed,
field.id,
response,
predictors,
seed.start,
perc.train,
n.fold,
n.models,
type.sample,
type.model,
type.metric,
str.model){
# Initialize output list
list.out <- list()
# Generate seeds
set.seed(seed.start)
seed.Model <- sample(x = 1000000, size = n.models, replace = FALSE)
# print(paste0(c('Seed.model: ', seed.Model), collapse = " "))
# Separate loops based on binary/multiclass model
if (str.model == 'binary') {
print('Binary model')
for(i in 1:length(seed.Model)){
# Generate binary model
model.out <- generate_binary_model(data.sample = data.sample,
response = response,
predictors = predictors,
seed.split = seed.Model[i],
perc.train = perc.train,
n.fold = n.fold,
type.sample = type.sample,
type.model = type.model,
type.metric = type.metric)
# Generate name assignments model and evaluation for output
name.out <- paste0('binary_seed_', seed.Model[i])
# Attach model and evaluation output to list
list.out[['Model']][[name.out]] <- model.out[[1]]
list.out[['Eval']][[name.out]] <- model.out[[2]]
# Declare output data
barriers.out <- data.predict %>% select(all_of({{field.id}}),
all_of({{type.predicted}}),
all_of({{type.observed}}),
all_of({{pass.observed}}),
all_of({{predictors}}))
# Initialize predicted passability fields
barriers.out <- barriers.out %>% mutate(Model_val = NA,
Pass_M = NA)
# Assign 0.0 passability rating to dams and falls and maintain known passability ratings
barriers.out <- barriers.out %>% mutate(Pass_M = ifelse((!!sym({{type.predicted}}) == 'DAM') | (!!sym({{type.predicted}}) == 'FAL'),
'0.0',
ifelse((is.na(Pass_M)) & (!!sym({{pass.observed}}) != '') & (!is.na(!!sym({{pass.observed}}))) & (!!sym({{pass.observed}}) != 'Unknown'),
!!sym({{pass.observed}}), NA)))
# Declare data for model prediction
barriers.predict <- barriers.out %>% filter(is.na(Pass_M))
# Predict barriers with model
barriers.predict$Model_val <- predict(object = model.out[[1]],
barriers.predict[,{{predictors}}],
type = 'raw')
# Assign passability based on barrier presence
barriers.predict <- barriers.predict %>% mutate(Pass_M = ifelse(Model_val == 'Absent', '1.0', '0.5'))
# Reduce join to only related data
barriers.join <- barriers.predict %>% select(all_of({{field.id}}), Model_val, Pass_M)
# print(head(barriers.join))
# Join predictions to output barriers
barriers.out <- barriers.out %>% left_join(barriers.join, by = field.id) %>%
mutate(Model_val = if_else(is.na(Model_val.x), Model_val.y, Model_val.x),
Pass_M = ifelse(is.na(Pass_M.x), Pass_M.y, Pass_M.x)) %>%
select(-Model_val.x, -Model_val.y, -Pass_M.x, -Pass_M.y)
# Attach predicted barriers to list
list.out[['Model_Results']][[name.out]] <- barriers.predict
list.out[['Barriers']][[name.out]] <- barriers.out
# Print completion log
print(paste0('COMPLETE: ', as.character(i), ' / ', as.character(length(seed.Model))))
}
} else if (str.model == 'multiclass'){
print('Multiclass model')
for(i in 1:length(seed.Model)){
# Generate binary model
model.out <- generate_multiClass_model(data.sample = data.sample,
response = response,
predictors = predictors,
seed.split = seed.Model[i],
perc.train = perc.train,
n.fold = n.fold,
type.sample = type.sample,
type.model = type.model,
type.metric = type.metric)
# Generate name assignments model and evaluation for output
name.out <- paste0('multiclass_seed_', seed.Model[i])
# Attach model and evaluation output to list
list.out[['Model']][[name.out]] <- model.out[[1]]
list.out[['Eval']][[name.out]] <- model.out[[2]]
# Declare output data
barriers.out <- data.predict %>% select(all_of({{field.id}}),
all_of({{type.predicted}}),
all_of({{type.observed}}),
all_of({{pass.observed}}),
all_of({{predictors}}))
# Initialize predicted passability fields
barriers.out <- barriers.out %>% mutate(Model_val = NA,
Pass_M = NA)
# Assign 0.0 passability rating to dams and falls and maintain known passability ratings
barriers.out <- barriers.out %>% mutate(Pass_M = ifelse((!!sym({{type.predicted}}) == 'DAM') | (!!sym({{type.predicted}}) == 'FAL'),
'0.0',
ifelse((is.na(Pass_M)) & (!!sym({{pass.observed}}) != '') & (!is.na(!!sym({{pass.observed}}))) & (!!sym({{pass.observed}}) != 'Unknown'),
!!sym({{pass.observed}}), NA)))
# Declare data for model prediction
barriers.predict <- barriers.out %>% filter(is.na(Pass_M))
# Predict barriers with model
barriers.predict$Model_val <- predict(object = model.out[[1]],
barriers.predict[,{{predictors}}],
type = 'raw')
# Assign passability based on barrier presence
barriers.predict <- barriers.predict %>% mutate(Pass_M = as.character(gsub('P_', "", Model_val)))
# Reduce join to only related data
barriers.join <- barriers.predict %>% select(all_of({{field.id}}), Model_val, Pass_M)
# print(head(barriers.join))
# Join predictions to output barriers
barriers.out <- barriers.out %>% left_join(barriers.join, by = field.id) %>%
mutate(Model_val = if_else(is.na(Model_val.x), Model_val.y, Model_val.x),
Pass_M = ifelse(is.na(Pass_M.x), Pass_M.y, Pass_M.x)) %>%
select(-Model_val.x, -Model_val.y, -Pass_M.x, -Pass_M.y)
# Attach predicted barriers to list
list.out[['Model_Results']][[name.out]] <- barriers.predict
list.out[['Barriers']][[name.out]] <- barriers.out
# Print completion log
print(paste0('COMPLETE: ', as.character(i), ' / ', as.character(length(seed.Model))))
}
} else {
print('Unsupported model type')
}
# Return output
return(list.out)
}
# Test function
barriers.test <- generate_modeled_barriers(data.sample = test.data,
response = test.response,
predictors = test.predictors,
perc.train = test.perc.train,
n.fold = test.n.fold,
type.sample = test.type.sample,
type.model = test.type.model,
type.metric = test.type.metric,
data.predict = test.predict,
seed.start = test.seed.start,
n.models = test.n.models,
str.model = test.str.model,
type.observed = test.type.observed,
type.predicted = test.type.predicted,
pass.observed = test.pass.observed,
field.id = test.field.id)
# INPUTS: MULTICLASS MODEL TESTING
test.data <- data.sample %>% mutate(Pass_WDFG = paste0('P_', Pass_WDFG))
test.response <- 'Pass_WDFG'
test.predictors <- c('Barrier_Predicted', 'Elev_m', 'Slope_site_perc',
'Slope_reach_perc', 'Slope_segment_perc', 'Qmad_cfs')
test.seed.split <- 687
test.perc.train <- 0.7
test.n.fold <- 5
test.type.sample <- 'up'
test.type.model <- 'gbm'
test.type.metric <- 'ROC'
# Set inputs - generate_modeled_barriers
test.predict <- data.barriers %>% select(UID, Barrier_Predicted, Barrier_Observed, Pass_WDFG,
Elev_m, Slope_site_perc, Slope_reach_perc,
Slope_segment_perc, Qmad_cfs)
test.seed.start <- 222
test.n.models <- 2
test.str.model <- 'multiclass'
test.type.predicted <- 'Barrier_Predicted'
test.type.observed <- 'Barrier_Observed'
test.pass.observed <- 'Pass_WDFG'
test.field.id <- 'UID'
generate_modeled_barriers <- function(data.sample,
data.predict,
type.predicted,
type.observed,
pass.observed,
field.id,
response,
predictors,
seed.start,
perc.train,
n.fold,
n.models,
type.sample,
type.model,
type.metric,
str.model){
# Initialize output list
list.out <- list()
# Generate seeds
set.seed(seed.start)
seed.Model <- sample(x = 1000000, size = n.models, replace = FALSE)
# print(paste0(c('Seed.model: ', seed.Model), collapse = " "))
# Separate loops based on binary/multiclass model
if (str.model == 'binary') {
print('Binary model')
for(i in 1:length(seed.Model)){
# Generate binary model
model.out <- generate_binary_model(data.sample = data.sample,
response = response,
predictors = predictors,
seed.split = seed.Model[i],
perc.train = perc.train,
n.fold = n.fold,
type.sample = type.sample,
type.model = type.model,
type.metric = type.metric)
# Generate name assignments model and evaluation for output
name.out <- paste0('binary_seed_', seed.Model[i])
# Attach model and evaluation output to list
list.out[['Model']][[name.out]] <- model.out[[1]]
list.out[['Eval']][[name.out]] <- model.out[[2]]
# Declare output data
barriers.out <- data.predict %>% select(all_of({{field.id}}),
all_of({{type.predicted}}),
all_of({{type.observed}}),
all_of({{pass.observed}}),
all_of({{predictors}}))
# Initialize predicted passability fields
barriers.out <- barriers.out %>% mutate(Model_val = NA,
Pass_M = NA)
# Assign 0.0 passability rating to dams and falls and maintain known passability ratings
barriers.out <- barriers.out %>% mutate(Pass_M = ifelse((!!sym({{type.predicted}}) == 'DAM') | (!!sym({{type.predicted}}) == 'FAL'),
'0.0',
ifelse((is.na(Pass_M)) & (!!sym({{pass.observed}}) != '') & (!is.na(!!sym({{pass.observed}}))) & (!!sym({{pass.observed}}) != 'Unknown'),
!!sym({{pass.observed}}), NA)))
# Declare data for model prediction
barriers.predict <- barriers.out %>% filter(is.na(Pass_M))
# Predict barriers with model
barriers.predict$Model_val <- predict(object = model.out[[1]],
barriers.predict[,{{predictors}}],
type = 'raw')
# Assign passability based on barrier presence
barriers.predict <- barriers.predict %>% mutate(Pass_M = ifelse(Model_val == 'Absent', '1.0', '0.5'))
# Reduce join to only related data
barriers.join <- barriers.predict %>% select(all_of({{field.id}}), Model_val, Pass_M)
# print(head(barriers.join))
# Join predictions to output barriers
barriers.out <- barriers.out %>% left_join(barriers.join, by = field.id) %>%
mutate(Model_val = if_else(is.na(Model_val.x), Model_val.y, Model_val.x),
Pass_M = ifelse(is.na(Pass_M.x), Pass_M.y, Pass_M.x)) %>%
select(-Model_val.x, -Model_val.y, -Pass_M.x, -Pass_M.y)
# Attach predicted barriers to list
list.out[['Model_Results']][[name.out]] <- barriers.predict
list.out[['Barriers']][[name.out]] <- barriers.out
# Print completion log
print(paste0('COMPLETE: ', as.character(i), ' / ', as.character(length(seed.Model))))
}
} else if (str.model == 'multiclass'){
print('Multiclass model')
for(i in 1:length(seed.Model)){
# Generate binary model
model.out <- generate_multiClass_model(data.sample = data.sample,
response = response,
predictors = predictors,
seed.split = seed.Model[i],
perc.train = perc.train,
n.fold = n.fold,
type.sample = type.sample,
type.model = type.model,
type.metric = type.metric)
# Generate name assignments model and evaluation for output
name.out <- paste0('multiclass_seed_', seed.Model[i])
# Attach model and evaluation output to list
list.out[['Model']][[name.out]] <- model.out[[1]]
list.out[['Eval']][[name.out]] <- model.out[[2]]
# Declare output data
barriers.out <- data.predict %>% select(all_of({{field.id}}),
all_of({{type.predicted}}),
all_of({{type.observed}}),
all_of({{pass.observed}}),
all_of({{predictors}}))
# Initialize predicted passability fields
barriers.out <- barriers.out %>% mutate(Model_val = NA,
Pass_M = NA)
# Assign 0.0 passability rating to dams and falls and maintain known passability ratings
barriers.out <- barriers.out %>% mutate(Pass_M = ifelse((!!sym({{type.predicted}}) == 'DAM') | (!!sym({{type.predicted}}) == 'FAL'),
'0.0',
ifelse((is.na(Pass_M)) & (!!sym({{pass.observed}}) != '') & (!is.na(!!sym({{pass.observed}}))) & (!!sym({{pass.observed}}) != 'Unknown'),
!!sym({{pass.observed}}), NA)))
# Declare data for model prediction
barriers.predict <- barriers.out %>% filter(is.na(Pass_M))
# Predict barriers with model
barriers.predict$Model_val <- predict(object = model.out[[1]],
barriers.predict[,{{predictors}}],
type = 'raw')
# Assign passability based on barrier presence
barriers.predict <- barriers.predict %>% mutate(Pass_M = as.character(gsub('P_', "", Model_val)))
# Reduce join to only related data
barriers.join <- barriers.predict %>% select(all_of({{field.id}}), Model_val, Pass_M)
# print(head(barriers.join))
# Join predictions to output barriers
barriers.out <- barriers.out %>% left_join(barriers.join, by = field.id) %>%
mutate(Model_val = if_else(is.na(Model_val.x), Model_val.y, Model_val.x),
Pass_M = ifelse(is.na(Pass_M.x), Pass_M.y, Pass_M.x)) %>%
select(-Model_val.x, -Model_val.y, -Pass_M.x, -Pass_M.y)
# Attach predicted barriers to list
list.out[['Model_Results']][[name.out]] <- barriers.predict
list.out[['Barriers']][[name.out]] <- barriers.out
# Print completion log
print(paste0('COMPLETE: ', as.character(i), ' / ', as.character(length(seed.Model))))
}
} else {
print('Unsupported model type')
}
# Return output
return(list.out)
}
# Test function
barriers.test <- generate_modeled_barriers(data.sample = test.data,
response = test.response,
predictors = test.predictors,
perc.train = test.perc.train,
n.fold = test.n.fold,
type.sample = test.type.sample,
type.model = test.type.model,
type.metric = test.type.metric,
data.predict = test.predict,
seed.start = test.seed.start,
n.models = test.n.models,
str.model = test.str.model,
type.observed = test.type.observed,
type.predicted = test.type.predicted,
pass.observed = test.pass.observed,
field.id = test.field.id)
barriers.test$Eval$multiclass_seed_790782
barriers.test$Eval$multiclass_seed_917522
View(barriers.test$Barriers$multiclass_seed_790782)
# INPUTS: BINARY MODEL TESTING
test.data <- data.sample %>% mutate(Pass_WDFG = paste0('P_', Pass_WDFG))
test.response <- 'Barrier_Present'
test.predictors <- c('Barrier_Predicted', 'Elev_m', 'Slope_site_perc',
'Slope_reach_perc', 'Slope_segment_perc', 'Qmad_cfs')
test.seed.split <- 687
test.perc.train <- 0.7
test.n.fold <- 5
test.type.sample <- 'down'
test.type.model <- 'gbm'
test.type.metric <- 'ROC'
# Set inputs - generate_modeled_barriers
test.predict <- data.barriers %>% select(UID, Barrier_Predicted, Barrier_Observed, Pass_WDFG,
Elev_m, Slope_site_perc, Slope_reach_perc,
Slope_segment_perc, Qmad_cfs)
test.seed.start <- 222
test.n.models <- 2
test.str.model <- 'binary'
test.type.predicted <- 'Barrier_Predicted'
test.type.observed <- 'Barrier_Observed'
test.pass.observed <- 'Pass_WDFG'
test.field.id <- 'UID'
# Test function
barriers.test <- generate_modeled_barriers(data.sample = test.data,
response = test.response,
predictors = test.predictors,
perc.train = test.perc.train,
n.fold = test.n.fold,
type.sample = test.type.sample,
type.model = test.type.model,
type.metric = test.type.metric,
data.predict = test.predict,
seed.start = test.seed.start,
n.models = test.n.models,
str.model = test.str.model,
type.observed = test.type.observed,
type.predicted = test.type.predicted,
pass.observed = test.pass.observed,
field.id = test.field.id)
barriers.test$Eval$multiclass_seed_790782
barriers.test$Eval$binary_seed_790782
barriers.test$Eval$binary_seed_917522
